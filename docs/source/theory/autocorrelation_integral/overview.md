# Overview

The goal of Stacie is to estimate the integral of the autocorrelation function
of a physical continuous time-dependent function with an infinite domain.
In computational studies, however, one resorts to discrete and finite time-dependent sequences.
We first formulate Stacie's goal in the continuous case
and then reformulate it in the discrete case.

## Continuous time, infinite domain

Consider an observation of a time-dependent function $\hat{x}(t)$,
which is generated by a stochastic process.
The integral of the autocorrelation function is defined as:

$$
\mathcal{I} =
    F \int_{-\infty}^{\infty}
    \cov \bigl[ \hat{x}(t) \,,\,\hat{x}(t + \Delta_t) \bigr]
    \, \mathrm{d}\Delta_t
$$

A prefactor $F$ is usually present,
for example containing a temperature and/or a volume in Green-Kubo formalisms.
The integrand is the autocorrelation function, $c(\Delta_t)$,
of the time-dependent input $\hat{x}(t)$.
The expectation value is obtained by averaging over all times $t$
and all observations of $\hat{x}(t)$.
Let $C(f)$ be the Fourier transform of the autocorrelation function:

$$
C(f)=\mathcal{F}[c](f)=\int_{-\infty}^\infty c(\Delta_t) e^{-i2\pi f \Delta_t} \mathrm{d} \Delta_t
$$

Then $\mathcal{I}$ is simply the DC component,
i.e., the zero-frequency limit of this Fourier transform:

$$
\mathcal{I} = F C(0)
$$

At first glance, this result seems trivial,
with no added value over the original form of the integral.
For numerical applications, this is actually a useful identity,
since autocorrelation functions are typically computed using the Fast Fourier Transform method.
It is computed with a forward and an inverse transform, after which $\mathcal{I}$ can be estimated.
When $\mathcal{I}$ is derived from the Fourier transform, the inverse can be skipped.
As we will see later, there are other advantages to using this limit to compute the integral.

:::{note}
Some derivations of Green-Kubo relations of transport properties,
conventionally formulated as integrals of autocorrelation functions,
also express them as the zero-frequency limit of an appropriate spectrum
{cite:p}`hansen_2013_theory`.
:::

One can always rewrite the autocorrelation integral
as a so-called Einstein relation, i.e.,
as the limit of a mean-square displacement {cite:p}`hansen_2013_theory`:

$$
    \mathcal{I} =
        \lim_{\Delta_t \rightarrow \infty} \frac{F}{\Delta_t}
        \mean\Bigl[\bigl|\hat{y}(t_0 + \Delta_t) - \hat{y}(t_0)\bigr|^2\Bigr]
$$

where $y$ is the antiderivative of $x$:

$$
    x = \frac{\mathrm{d}y}{\mathrm{d}t}
$$

Stacie can also be used to evaluate such limits,
by using samples of the time derivatives of $y$
as input to the power spectrum computation.

## Discretized time, periodic sequences

A similar result can be formulated for discrete and periodic sequences, $\hat{x}_n$.
Such a discrete sequence is obtained by discretizing the time axis
with a time step $h$ and a time origin $t_0$:

$$
\hat{x}_n = \hat{x}(t_0 + nh) \quad \forall\, n=0 \ldots N-1
$$

The underlying continuous function $\hat{x}(t)$, and thus $\hat{x}_n$, are not necessarily periodic.
Because we intend to use the discrete Fourier transform and rely on its well-known properties,
we will assume in the derivations that $\hat{x}_n$ is periodic with period $N$,
and discuss the artifacts due to lack of periodicity later.
In practice, such artifacts are negligible and only noticeable at higher frequencies,
far away from the zero-frequency limit.

The autocorrelation integral is approximated with a simple quadrature rule:

$$
\mathcal{I} = F h \sum_{\Delta=0}^{N-1} \cov \bigl[ \hat{x}_n \,,\, \hat{x}_{n+\Delta} \bigr]
$$

The summand is the discrete autocorrelation function, $c_\Delta$.
The expectation value is not only an average over $n$,
but also over all possible realizations of the input sequence.
For example, one can consider different non-overlapping sequences by taking different time origins.
Furthermore, the sequences are generated by a stochastic process
over which one can compute averages.

Let $C_k$ be the discrete Fourier transform of the autocorrelation function:

$$
C_k = F h \sum_{\Delta=0}^{N-1} c_\Delta \omega^{-kn}
$$

with $\omega = \exp(i 2\pi/N)$.
This is also known as the power spectrum:

$$
C_k = \frac{F h}{N}\mean \bigl[|\hat{X}_k|^2\bigr]
$$

with

$$
\hat{X}_k = \sum_{n=0}^{N-1} (\hat{x}_n - \mean[\hat{x}_n]) \omega^{-kn}
$$

The division by $N$ comes from the fact that the autocorrelation function is defined as
an average over all $n$ (and all realizations of $\hat{x}_n$).
We have included the prefactor $F h$ in the definition of the power spectrum,
so that $\mathcal{I} = C_0$.
Plotting an estimated spectrum with this normalization
has the advantage of giving a quick visual estimate of $\mathcal{I}$ with the appropriate units.

A direct computation of $\hat{C}_0$ for a limited number of input sequences
would not yield an effective estimate of $\mathcal{I}$.
At best, such an estimate would have a high variance.
In some applications, the DC component is not usable at all
because the mean $\mean[\hat{x}_n]$ is unknown a priori and cannot simply be subtracted.
(An unknown mean does not affect the spectrum for $k \neq 0$.)

To reduce the variance of the estimate of $\mathcal{I}$, Stacie derives the zero-frequency limit from
the low-frequency part of the power spectrum.
The following theory sections explain how this estimate can be made robustly.
In summary, a broadly applicable  [model](model.md) for the low-frequency spectrum is developed,
assuming that the autocorrelation function has an exponentially decaying tail.
The three parameters in this model are estimated with likelihood maximization.
To express the likelihood, one requires the [statistics](statistics.md) of the estimated spectrum.
Finally, one must decide up to which [cutoff](cutoff.md) frequency the model will be fitted.
For cutoffs that are too high,
the model becomes too simple to describe all the features in the spectrum,
which leads to significant underfitting.
When the cutoff is too low,
too few data points are included to obtain a low-variance estimate of $\mathcal{I}$.
This is solved by considering multiple cutoff frequencies
and selecting the one that minimizes a simple underfitting criterion.
